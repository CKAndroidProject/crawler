> 原文链接: https://www.anquanke.com//post/id/201761 


# 探讨恶意软件检测中的对抗性样本


                                阅读量   
                                **353366**
                            
                        |
                        
                                                                                                                                    ![](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsQAAA7EAZUrDhsAAAANSURBVBhXYzh8+PB/AAffA0nNPuCLAAAAAElFTkSuQmCC)
                                                                                            



##### 译文声明

本文是翻译文章，文章原作者Octavian Suciu，Scott E. Coull，Jeffrey Johns，文章来源：arxiv.org
                                <br>原文地址：[https://arxiv.org/pdf/1810.08280.pdf](https://arxiv.org/pdf/1810.08280.pdf)

译文仅供参考，具体内容表达以及含义原文为准

[![](https://p3.ssl.qhimg.com/t0106033c0972d4009a.jpg)](https://p3.ssl.qhimg.com/t0106033c0972d4009a.jpg)



卷积神经网络（CNN）体系结构正越来越多地应用于新领域，例如恶意软件检测，该领域能够从可执行文件中提取原始字节来学习恶意行为。这些架构无需进行特征工程即可达到令人印象深刻的性能，但它们对活动攻击者的鲁棒性还有待了解。

此类恶意软件检测器可能会以对分类模型的对抗性干扰的形式面临新的攻击媒介。现有规避攻击会导致测试时实例错误分类的不适用，已经针对图像分类器进行了广泛研究来避免这种攻击。因为输入语义阻止了二进制文件的任意更改。

本文探讨了恶意软件检测的对抗样本领域。通过在生产规模的数据集上训练现有模型，表明以前的某些攻击没有最初报告的有效，同时还强调了架构上的弱点，这些弱点促进了用于恶意软件分类的新攻击策略。最后探讨了不同的攻击策略如何通用化，旨在提高其有效性时的权衡以及单步骤攻击的可传递性。



## 0x01 Introduction

卷积神经网络（CNN）分类器的流行已导致其在历史上一直具有对抗性的领域中被采用，例如恶意软件检测。对抗性机器学习的最新进展凸显了分类器在面对对抗性样本时的弱点。一种此类攻击是逃避（evasion），它会在测试时间实例上起作用。

攻击者修改了实例（也称为对抗性样本），从而使受害者分类器对它们进行了错误分类，即使它们仍然类似于其原始表示形式。最新的攻击主要集中在图像分类器上，其中攻击会向输入像素添加较小的扰动，从而导致受害者分类器特征空间发生较大变化，从而有可能在分类决策边界上移动。扰动不会改变图像的语义，因为人类预言机容易识别与图像相关的原始标签。

在恶意软件检测的情况下，对抗性样本可能代表确定逃避此类系统的攻击者的附加攻击媒介。但是，特定于域的挑战限制了针对此任务针对图像分类器设计的现有攻击的适用性。首先，二进制文件的严格语义不允许在输入空间中进行任意扰动。这是因为相邻字节之间存在结构上的相互依赖关系，并且对字节值的任何更改都可能破坏可执行文件的功能。

其次，代表性数据集或严格的公共模型的有限可用性限制了现有研究的普遍性。现有的攻击使用在非常小的数据集上训练的受害者模型，并对它们的策略做出各种假设。因此，跨生产规模模型的泛化有效性以及各种提议的策略之间的权衡尚待评估。

本文阐明了针对基于CNN的恶意软件检测器的对抗样本的一般性。通过在1250万个二进制文件的生产规模数据集上进行训练，能够观察到对抗性攻击的有趣特性，表明当使用小型数据集进行训练时，它们的有效性可能会被错误估计，并且单步攻击对于鲁棒性更有效在较大的数据集上训练模型。

•测量数据集中的对抗性攻击的一般性，重点介绍各种策略之间的共同属性和取舍。

•发现了已发布的CNN架构的架构弱点，该弱点促进了现有的攻击策略。

•调查了在不同数据集上训练的模型之间单步对抗性示例的可传递性。



## 0x02 Background

事实证明，CNN架构在常见的视觉任务（例如图像分类）中非常成功。这导致在其他领域和主要领域的采用率提高，其中一个示例是从字符级功能进行文本分类，结果与本文讨论的恶意软件分类问题极为相似。

在此设置中，自然语言文档表示为字符序列，而CNN应用于该一维字符流。这种方法背后的直觉是，CNN能够通过观察从单个字符中提取的原始信号的组成来自动学习复杂的功能，例如单词或单词序列。这种方法还避免了定义语言语义规则的要求，并且能够容忍功能中的异常，例如单词拼写错误。分类管道首先将每个字符编码为固定大小的嵌入向量。嵌入序列充当一组卷积层的输入，与池化层混合，然后是完全连接的层。

卷积层充当接收器，从输入实例中选择特定特征，而池化层充当向下采样的过滤器特征空间。完全连接的层充当实例内部特征表示的非线性分类器。

### <a class="reference-link" name="A.%E6%81%B6%E6%84%8F%E8%BD%AF%E4%BB%B6%E5%88%86%E7%B1%BB%E7%9A%84CNN"></a>A.恶意软件分类的CNN

与这种方法类似，安全社区探索了CNN在恶意软件检测任务中的适用性。在原始“字节”表示形式上、或在在反汇编函数上使用CNN。在这项工作中专注于原始字节表示。

与文本域类似，可执行文件可以概念化为按字节顺序排列的字节序列，这些字节序列排列为更高级别的功能，例如指令或功能。通过允许分类器自动学习表示恶意的特征，该方法避免了典型的恶意软件分类任务的劳动密集型特征工程过程。过去，人工特征工程被证明是具有挑战性的，并导致了反病毒开发人员和旨在逃避它们的攻击者之间的军备竞赛。但是，面对逃避时这些自动学习功能的健壮性尚待了解。

[![](https://p3.ssl.qhimg.com/t01ca47f459aded9773.png)](https://p3.ssl.qhimg.com/t01ca47f459aded9773.png)

在本文中，将重点放在基于字节的卷积神经网络进行恶意软件检测，从而探索逃避攻击，该网络称为MalConv，其体系结构如上图所示。MalConv从可移植可执行文件（PE）中读取最多2MB的原始字节值作为输入，将专有的填充令牌附加到小于2MB的文件中，并截断较大文件中的多余字节。然后将固定长度的序列转换为嵌入表示，其中每个字节都映射到8维嵌入向量。

然后，在通过最终的完全连接层进行分类之前，将这些嵌入先通过门控卷积层，再经过时间最大池化层。每个卷积层使用500字节的内核大小，跨度为500（即非重叠窗口），并且128个过滤器中的每一个都通过最大池化层。

这产生了一个独特的体系结构功能，将在结果中重新访问：每个合并的过滤器都映射回特定的500字节序列，并且最多有128个这样的序列对整个输入进行最终分类。他们在一组77,349个样品上报告的结果达到了0.909的平衡准确度和0.982的曲线下面积（AUC）。

### <a class="reference-link" name="B.%E5%AF%B9%E6%8A%97%E6%80%A7%E4%BA%8C%E8%BF%9B%E5%88%B6%E6%96%87%E4%BB%B6"></a>B.对抗性二进制文件

与对图像的回避攻击不同，更改PE文件原始字节的攻击必须保持原始文件的语法和语义保真度。便携式可执行（PE）标准为这些文件定义了固定的结构。 PE文件包含一个开头的头文件，该文件头包含文件元数据和指向文件各部分的指针，其后是可变长度部分，其中包含实际程序代码和数据。

任意更改字节可能会破坏二进制文件的恶意功能，甚至更糟糕的是，根本无法加载二进制文件。因此，仅限于静态分析二进制文件的攻击者对他们可以修改的功能的利用有限。

最近的工作提出了解决这些局限性的两种策略。第一个通过在二进制文件的末尾附加对抗性噪声来避免此问题。由于附加的对抗性字节不在PE文件的定义边界内，因此它们的存在不会影响二进制文件的功能，并且字节的语法（即有效的指令和参数）也没有固有的限制。

但是，要权衡的是，附加字节对最终分类的影响被原始样本中存在的特征（这些特征保持不变）所抵消。

正如将看到的，这些攻击利用了MalConv体系结构中存在的与位置无关的特征检测器中的某些漏洞。第二种策略试图在可执行文件中发现未映射到内存的区域，并且在修改后不会影响预期的行为。

但是，此方法与附加策略相比的效用之前尚未研究过。在本文中大规模评估了这两种策略的比较有效性，并强调了它们在各个模型之间的可迁移性，以及可能影响它们总体适用性的权衡取舍。

### <a class="reference-link" name="C.%E6%95%B0%E6%8D%AE%E9%9B%86"></a>C.数据集

为了评估针对Mal Conv架构的规避攻击的成功性，利用了三个数据集。首先，从各种来源收集了1630万PE文件，包括VirusTotal，Reversing Labs和专有FireEye数据。数据用于创建12.5M训练样本和3.8M测试样本的生产质量数据集，称其为Full数据集。语料库在训练集中包含220万个恶意软件样本，在测试中包含120万个恶意软件样本。

使用基于恶意软件家族的分层采样技术，从超过3300万个样本的更大池中创建了数据集。使用分层抽样可确保对数据集中存在的标准二进制“类型”进行统一覆盖，同时还可以限制某些过高表示的类型（例如，流行的恶意软件家族）的偏见。

其次，利用EMBER数据集，该数据集是一个公开可用的数据集，包含1.1M个PE文件，其中900K用于训练。在此数据集上，使用随数据集发布的经过预先训练的MalConv模型。此外还创建了一个较小的数据集，将其称为Mini数据集。

Mini数据集是通过对Full数据集中的4,000个优质软件和4,598个恶意软件样本进行采样而创建的。请注意，两个数据集均遵循严格的时间划分，其中严格晚于训练数据地观察到测试数据。使用Mini数据集来探究先前工作是否证明了攻击结果。将推广到生产质量模型，或者它们是否是数据集属性的工件。



## 0x03 Baseline Performance

为了验证对MalConv体系结构的实现，在Mini数据集和Full数据集上训练了分类器，而忽略了建议的DeCov正则化加法。实现使用基于动量的优化器，该优化器具有衰减，批处理大小为80个实例。在Mini数据集上训练了10个完整周期，还对Full数据集进行了10个时期的训练，但由于验证损失很小，因此提前停止了该过程。

为了评估和比较两个模型的性能，在整个完整测试集上对其进行了测试。在Full数据集上训练的模型达到0.89的准确度和0.97的AUC，这与原始论文中发表的结果相似。毫不奇怪，Mini模型的健壮性要差得多，准确度为0.73，AUC为0.82。据报道，在EMBER上训练的MalConv模型在相应的测试集上达到0.99 AUC。



## 0x04 Attack Strategies

### <a class="reference-link" name="A.%E9%99%84%E5%8A%A0%E6%94%BB%E5%87%BB"></a>A.附加攻击

通过将对抗性噪声附加到原始文件中来解决PE文件的语义完整性约束。首先介绍Kolosnjaji等人首先提出的两次攻击。并针对MalConv进行了评估，随后是用来评估分类器鲁棒性的两种策略

**a）随机附加：**此攻击通过附加从均匀分布中采样的字节值来起作用。此基准攻击可衡量附加攻击可如何轻松抵消源自文件长度的特征，并有助于比较随机附加噪声下来自更复杂附加策略的实际对抗性收益。

**b）梯度附加：**梯度附加策略使用输入的梯度值来指导附加字节值的变化。该算法将numBytes附加到候选日期样本，并在numIter迭代中或直到规避受害者分类器之前更新其值。输出相对于输入层的坡度表示在输入空间中最小化输出所需的更改方向，因此将其值推向良性类别。从随机值开始，迭代地更新所有附加字节的表示形式。

但是，由于将输入字节映射到MalConv中的离散嵌入表示形式，因此端到端体系结构变得不可微，并且其输入梯度无法进行解析计算。因此，此攻击使用启发式方法代替更新嵌入向量，并将其在字节空间中沿嵌入梯度的方向离散化为最接近的字节值。攻击需要numBytes * numIter梯度计算，并在最坏的情况下更新附加字节，这对于大型网络而言可能是非常昂贵的。

**c）良性附加：**此策略可以观察MalConv体系结构（特别是其临时最大池层）对在文件末尾重用良性字节序列的攻击的敏感性。攻击从良性实例的开头获取字节，并将其附加到恶意实例的末尾。这种攻击背后的直觉是文件的前导字节，尤其是PE标头，对分类决策最有影响。因此，它通过附加高影响力的良性字节来指示是否可以抵消目标的恶意行为。

[![](https://p2.ssl.qhimg.com/t0104f566db728dc0ec.png)](https://p2.ssl.qhimg.com/t0104f566db728dc0ec.png)

**d）FGM附加：**基于观察到的梯度附加攻击的收敛时间随附加字节数线性增长，提出了“一次性” FGM附加攻击，它最初是对快速梯度方法（FGM）的一种改进在中描述。 Frem攻击针对恶意软件域的适应在一种旨在生成小型对抗有效载荷的迭代算法中。相反，本文攻击策略旨在强调模型的脆弱性，这是对抗性杠杆作用不断增强的函数。伪代码在算法1中进行了描述。

攻击始于将numBytes随机字节附加到原始样本x0并使用FGM规定的策略对其进行更新。攻击使用相对于目标标签的输出分类损失l。 FGM在使输入上的l最小的方向上按照用户指定的量更新每个嵌入值，这由梯度的符号指示。尽管此攻击框架独立于用于量化扰动的距离度量，但实验使用L∞。

为了避免不可微问题，攻击在嵌入空间中对附加字节执行了基于梯度的更新，同时使用L2距离度量将更新后的值映射到EMBEDDINGMAPPING中最接近的字节值表示形式。可以使用更复杂的映射来确保更新对于减少损失保持有益。但是从经验上观察到，指标选择不会显着影响单步攻击的结果。

### <a class="reference-link" name="B.%E9%99%84%E5%8A%A0%E7%AD%96%E7%95%A5%E7%9A%84%E5%B1%80%E9%99%90%E6%80%A7"></a>B.附加策略的局限性

除了无法将字节附加到已超出模型最大大小的文件（例如，对于MalConv，为2MB）之外，基于附加的攻击还会受到其他限制。在MalConv体系结构中，PE文件被分解为长度为500的非重叠字节序列。最大文件大小为2MB，最多对应4195个这样的序列。该模型使用128个特征，这意味着在4,195个序列中只能选择128个。

在下图中，选择了200个候选恶意软件样本的随机集合，并检查了文件大小分布以及该模型平均选择了4,195个序列中的哪个。这表明，例如，虽然二进制文件中的前1,000个序列（0.5 MB）对应于分类器实际功能的79％，但只有55％的文件小于该分类器。

另外，13％的实例根本无法受到攻击，因为它们大于分类器的最大文件大小。结果表明，不仅附加的字节需要抵消很大一部分原始区分特征，而且由于其重要性，直接攻击这些区分特征的字节序列可能会放大攻击效果。在这种直觉的驱使下，继续描述一种攻击策略，该策略将利用二进制文件的现有字节，而对程序的功能没有副作用。

[![](https://p1.ssl.qhimg.com/t01f1dbb2157617b963.png)](https://p1.ssl.qhimg.com/t01f1dbb2157617b963.png)

### <a class="reference-link" name="C.%E6%9D%BE%E5%BC%9B%E6%94%BB%E5%87%BB"></a>C.松弛攻击

**a）松弛FGM：**定义了一组松弛字节，攻击算法被允许在不破坏PE的情况下自由修改现有二进制文件中的字节。一旦识别出，则使用基于梯度的方法修改松弛字节。算法2中的SLACKATTACK函数突出显示了攻击体系结构。该算法与用于提取松弛字节的SLACKINDEXES方法或用于更新字节的GRA DIENTATTACK中的基于梯度的方法无关。

[![](https://p0.ssl.qhimg.com/t010d01151cf506c2f3.png)](https://p0.ssl.qhimg.com/t010d01151cf506c2f3.png)

在实验中使用了一种简单的技术，经验证明可以有效地找到足够大的松弛区域。此策略通过分析可执行文件的标头来提取可执行文件的相邻PE节之间的间隙。间隙是由编译器插入的，并且由于虚拟地址和乘法器在磁盘上的块大小上未对齐而存在。

将二进制文件中连续节之间的间隙大小计算为RawSize-V irtualSize，并通过该节的RawAddress + V irtualSize在二进制文件中定义其字节起始索引。通过组合所有松弛区域，SLACKINDEXES在文件的现有字节上返回一组索引，指示可以对其进行修改。该技术首先在中提到。但是以前尚未对其效果进行系统的评估以及松弛和追加策略之间的比较。

尽管可能使用更复杂的字节更新策略，并可能考虑到松弛区域所施加的有限杠杆作用，但使用了算法1中针对FGM追加攻击引入的技术，该技术被证明是有效的。与FGM Append一样，对允许的字节索引的嵌入执行更新，并且使用L2距离度量将更新后的值映射回字节值。



## 0x05 Results

在这里使用在Mini，EMBER和Full数据集上训练的模型，在相同的对抗条件下评估上一部分中描述的攻击。评估旨在回答以下问题：

•现有的攻击如何概括为在较大数据集上训练的分类器？

•健壮的MalConv架构对对抗性样本的脆弱性如何？

•基于松弛的攻击是否比附加攻击更有效？

•单步骤对抗性样本是否可以在模型之间转移？

为了重现先前的工作，如果文件大小小于990,000字节且被受害者正确分类为恶意软件，将从测试集中选择候选实例。随机选择400名候选人，并使用成功率（SR）（成功避开检测的对抗性样本的百分比）来衡量攻击的有效性。

### <a class="reference-link" name="A.%E9%99%84%E5%8A%A0%E6%94%BB%E5%87%BB"></a>A.附加攻击

通过更改附加字节数来评估对Mini，EMBER和Full数据集的基于附加的攻击，并在下表中汇总了结果。无论附加字节数如何，随机附加攻击在所有三个模型上均失败。该结果符合预期，表明MalConv模型不受随机噪声的影响，并且输入大小不在学习的功能之列。但是结果并不能增强Kolosnjaji等人先前发表的高达15％的成功率。

[![](https://p5.ssl.qhimg.com/t01f799581faebf9dcd.png)](https://p5.ssl.qhimg.com/t01f799581faebf9dcd.png)

随着Mini数据集上增加的字节数，Benign Append攻击的SR似乎逐渐增加，但是在EMBER和Full数据集上却没有显示出相同的行为。相反，在FGM Append攻击中，发现该攻击在Mini数据集上失败，而在EMBER上达到了33％的SR，在Full数据集上达到了71％的SR。这种自相矛盾的行为突出了大型，强大的数据集在评估对抗性攻击中的重要性。

攻击行为差异的原因之一是，使用Mini数据集（根据Kolosnjaji等人使用的数据集建模）训练的MalConv模型存在严重的过拟合问题。特别是，从Mini数据集中添加特定的良性字节序列的成功可能表明通用性差，而模型的容量与Mini数据集中的样本数量之间的脱节进一步证明了这一点。考虑到单步骤FGM攻击在EMBER和Full数据集上的成功，以及在Mini数据集上的失败，认为这些结果也可以通过Mini模型的通用性差来解释。单个梯度评估无法为攻击中进行的字节更改序列提供足够的信息。

每次更改单个字节后，重新计算梯度都将导致更高的攻击成功率。最后还观察到EMBER上的SR与完整模型之间存在较大差异，这与直觉相反地突出显示了在较大数据集上训练的模型更脆弱。

结果揭示了基于单步梯度的攻击的有趣特性：随着训练数据的增加，该模型将编码更多的顺序信息，并且单个梯度评估对于攻击更加有利。相反，在较不健壮的模型上彼此独立更新字节的成功可能性较小。

除了围绕数据集大小和组成的方法论问题外，结果还表明，即使给定足够大的自由度，即使训练有素的MalConv分类器也容易遭受附加攻击。确实，该体系结构使用500字节的卷积内核，步幅为500，并且整个文件具有单个最大池层，这意味着它不仅会查看有限的一组相对粗糙的功能，而且还会选择最佳的128个激活位置，与位置无关。

也就是说，一旦在FGM攻击中添加了足够多的附加字节，它们就会在max pool操作中迅速替换原始二进制文件中的合法功能。因此，该体系结构不对位置信息进行编码，这是证明可以利用的一个重大漏洞。

### <a class="reference-link" name="B.%E6%9D%BE%E5%BC%9B%E6%94%BB%E5%87%BB"></a>B.松弛攻击

对于与上述相同的实验设置，评估了针对EMBER和Full数据集的Slack FGM攻击。为了控制在松弛字节中添加的对抗性噪声量，使用参数在嵌入空间中围绕原始字节值定义L2。 FGM攻击提供的落在球内的那些值才视为松弛攻击，否则原始字节值将保留。

[![](https://p5.ssl.qhimg.com/t016972993eb7ee06a3.png)](https://p5.ssl.qhimg.com/t016972993eb7ee06a3.png)

如上图a所示，通过变化控制了可修改的可用松弛字节的百分比。对于平均修改14％（291/2103）松弛字节的攻击，SR的上限是EMBER的15％，而在Full上，SR的上限为58％（1117/1930）。尽管针对Full的攻击比EMBER更成功，但它也成功地按比例修改了更大数量的字节。观察到EMBER模型为松弛字节返回非常小的梯度值，表明它们对目标分类的重要性很低。结果还强化了关于FGM Append攻击的单个梯度评估的假设。

为了将Slack FGM与附加攻击进行比较，在图b和c中，将SR绘制为已修改字节数的函数。结果表明，尽管FGM Append攻击可以实现更高的SR，但它还需要进行大量的字节修改。在EMBER上，Slack FGM平均修改291个字节，这对应于FGM Append大约需要500个字节的SR。完全攻击时，对于相同的设置，平均1005个修改字节的SR达到27％的SR，而FGM Append的SR约为20％。

结果证实了最初直觉，即MalConv功能的粗略性质需要考虑卷积窗口内周围的上下文字节。在松弛攻击中，利用现有的上下文字节来放大FGM攻击的能力，而不必使用附加字节生成完整的500字节卷积窗口。

### <a class="reference-link" name="C.%E6%94%BB%E5%87%BB%E8%BD%AC%E7%A7%BB%E6%80%A7"></a>C.攻击转移性

进一步分析针对一个（源）模型针对另一（目标）模型生成的攻击样本的可传递性。使用EMBER和Full交替地充当源和目标进行了两个实验，并对成功规避源模型并且目标模型正确分类了原始（攻击前）样本的样本评估了FGM Append和Slack FGM攻击。

每组实验最多只能有2/400个样本逃避目标模型，表明这些单步样本无法在模型之间转移。该发现与先前对图像分类的对抗性示例的观察结果不一致，在该示例中，单步采样已成功跨模型转移。但是将对其他嵌入映射和更强大的迭代攻击进行系统的可移植性分析，以供将来使用。



## 0x06 Conclution

在本文中，针对基于深度学习的恶意软件检测器探索了对抗样本。实验表明，对使用小数据集训练的模型进行对抗性攻击的有效性并不总是能生成稳健的模型。还观察到MalConv体系结构不对有关输入功能的位置信息进行编码，因此容易受到基于附加的攻击。最后攻击突显了对抗性样本的威胁，它是逃避技术（例如运行时打包）的替代方法。
